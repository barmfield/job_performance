{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.repeat(['train','test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barmfield/anaconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (50,53,54,55,56,255,256,257,258,260,268,376) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_clean = pd.read_csv('hw4-trainingset-wsa2113.csv')\n",
    "train = train_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barmfield/anaconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (50,255,256,257,258,260,268,280) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "test_clean = pd.read_csv('hw4-testset-wsa2113.csv')\n",
    "test = test_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = pd.read_csv('CodeBook-SELECT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (20000, 380)\n",
      "test shape: (24500, 380)\n",
      "code book shape: (379, 2)\n"
     ]
    }
   ],
   "source": [
    "print('train shape:',train.shape)\n",
    "print('test shape:',test.shape)\n",
    "print('code book shape:',cb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:  \n",
    "* create baseline\n",
    "    * drop high null variables and rows\n",
    "* Data cleaning\n",
    "    * drop duplicate columns\n",
    "        * cntryid, cntryid_e\n",
    "        * drop cntryid, as it is less specific\n",
    "    * drop cols w/ high null %\n",
    "    * drop rows w/ high null %\n",
    "    * add is_null column for each category where value was null\n",
    "    * find cols with mixed types and correct\n",
    "    * convert numerical columns to int or float from objects\n",
    "    * categorical variables\n",
    "        * OHC categorical variables\n",
    "        * make sure dtypes match up across train and test\n",
    "    * missing data\n",
    "        * experiment imputing with mean and median\n",
    "            * check distribution of data; if there are big outliers, use median, if not, use mean\n",
    "        * check all cols which have missing data and see if that data should be captured in a new feature\n",
    "    * feature scaling\n",
    "        * **NOTE: split and scale at the same time**\n",
    "        * normalization --> min/max scaler\n",
    "        * standardization (z-score normalization)\n",
    "        * api\n",
    "            * column transformer\n",
    "                * numeric transformer\n",
    "                    * imputer\n",
    "                    * scaler\n",
    "                * categorical transformer\n",
    "                    * imputer\n",
    "                    * OHE\n",
    "    * dimensionality reduction\n",
    "        * PCA\n",
    "    * normalizing\n",
    "        * yeo-johnson power transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "* Remove columns\n",
    "    * Drop high % null cols and rows\n",
    "        * Threshold = 75%\n",
    "    * Drop columns unrelated to performance\n",
    "    * Drop target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split data into train, val, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 377)\n",
      "(20000,)\n",
      "(24500, 377)\n",
      "(24500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = train.drop(['uni','row','job_performance'], axis = 1)\n",
    "y_train = train['job_performance']\n",
    "X_test = test[X_train.columns]\n",
    "y_test = test['job_performance']\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3114.660665\n",
       "1    2561.324500\n",
       "2    2873.347766\n",
       "3    2713.175295\n",
       "4    2230.654274\n",
       "Name: job_performance, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,10))\n",
    "_ = ax.hist(y_train, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Identify categorical and numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_obj_cols = X_train.dtypes == object\n",
    "cat_cols = categorical_obj_cols[categorical_obj_cols==True].index.values\n",
    "num_cols = categorical_obj_cols[categorical_obj_cols==False].index.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fix columns with multiple data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    X_train[col] = X_train[col].astype('str')\n",
    "    \n",
    "for col in num_cols:\n",
    "    X_train[col] = X_train[col].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipeline\n",
    "    * impute nulls\n",
    "    * scale numerical columns\n",
    "    * OHE categorical columns\n",
    "    * Try with\n",
    "        * Lasso\n",
    "        * Ridge\n",
    "        * RandomForestRegressor\n",
    "        * SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def try_model(model, X, y):\n",
    "    scores = cross_val_score(model, X, y, cv=3, scoring='neg_mean_squared_error')\n",
    "    print('Average MSE = {:.2f} +/- {:.2f}'.format(-np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    \n",
    "# missing_transform = \n",
    "num_transform = Pipeline(\n",
    "    [\n",
    "        ('num_imputer', SimpleImputer(strategy='median')),\n",
    "        ('num_scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures())\n",
    "    ]\n",
    ")\n",
    "\n",
    "cat_transform = Pipeline(\n",
    "    [\n",
    "        ('nan_imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ('cat_scaler', StandardScaler(with_mean=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('num', num_transform, ~categorical_obj_cols),\n",
    "        ('cat', cat_transform, categorical_obj_cols),\n",
    "    ]\n",
    ")\n",
    "    \n",
    "# X_train_pr = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 6665)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso_alphas = np.logspace(-1, -.01, 10)\n",
    "lasso = LassoCV(alphas=lasso_alphas, cv=3, max_iter=10000, n_jobs=-1, random_state=0)\n",
    "lasso.fit(X_train_pr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_data = np.hstack((lasso.mse_path_,lasso.alphas_[:,np.newaxis]))\n",
    "lasso_data = np.hstack((lasso_data, \n",
    "                        np.array([lasso.alpha_ for _ in range(lasso.mse_path_.shape[0])])[:,np.newaxis]))\n",
    "lasso_cols = ['cv_'+str(i) for i in range(lasso.mse_path_.shape[1])]\n",
    "lasso_cols.append('alpha')\n",
    "lasso_cols.append('best_alpha')\n",
    "lasso_results = pd.DataFrame(data=lasso_data, columns=lasso_cols)\n",
    "lasso_results.to_csv('lasso_results.csv')\n",
    "lasso_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE = 124874.70 +/- 5820.21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "best_lasso_alpha = 0.977237\n",
    "best_lasso = Lasso(alpha=best_lasso_alpha, normalize=False, random_state=0)\n",
    "scores = cross_val_score(best_lasso, X_train_pr, y_train, cv=3, scoring='neg_mean_squared_error')\n",
    "print('Average MSE = {:.2f} +/- {:.2f}'.format(-np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([ 900.,  960., 1020., 1080., 1140., 1200., 1260., 1320., 1380.,\n",
       "       1440., 1500.]),\n",
       "    cv=None, fit_intercept=True, gcv_mode=None, normalize=False,\n",
       "    scoring=None, store_cv_values=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# ridge_alphas = np.logspace(-4, .01, 20)\n",
    "ridge_alphas = np.linspace(900,1500,11)\n",
    "ridge = RidgeCV(alphas=ridge_alphas, store_cv_values=True)\n",
    "ridge.fit(X_train_pr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv_results = np.mean(ridge.cv_values_, axis=0)[:,np.newaxis]\n",
    "ridge_data = np.hstack((ridge_cv_results,ridge_alphas[:,np.newaxis]))\n",
    "ridge_data = np.hstack((ridge_data, \n",
    "                        np.array([ridge.alpha_ for _ in range(ridge_data.shape[0])])[:,np.newaxis]))\n",
    "ridge_cols = ['mse','alpha','best_alpha']\n",
    "ridge_results = pd.DataFrame(data=ridge_data, columns=ridge_cols)\n",
    "ridge_results.to_csv('ridge_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE = 366209.79 +/- 314504.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "best_ridge_alpha = ridge.alpha_\n",
    "best_ridge = Ridge(alpha=best_ridge_alpha, random_state=0)\n",
    "scores = cross_val_score(best_ridge, X_train_pr, y_train, cv=3, scoring='neg_mean_squared_error')\n",
    "print('Average MSE = {:.2f} +/- {:.2f}'.format(-np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF Regressor  \n",
    "* Guidance on gridsearching RandomForestRegressor : https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap\n",
    "              }\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "rscv = RandomizedSearchCV(\n",
    "    rfr,\n",
    "    param_distributions=random_grid,\n",
    "    n_iter=100,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "rscv.fit(X_train_pr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results=pd.DataFrame(rscv.cv_results)\n",
    "rf_results.to_csv('rf_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE = 120600.63\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "Xy_train_xgb = xgb.DMatrix(data=X_train_pr, label=y_train)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "params = {\"objective\":\"reg:squarederror\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=Xy_train_xgb, params=params, nfold=3, num_boost_round=50,\n",
    "                    early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "\n",
    "mse = cv_results[\"test-rmse-mean\"].tail(1).values[0]**2\n",
    "print('Average MSE = {:.2f}'.format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take 2  \n",
    "* univariate statistics\n",
    "* Incorporate PCA into pipeline\n",
    "* Create new encoding for high cardinality categorical columns\n",
    "* add missing value column for np.nan values\n",
    "* Add feature interactions for numerical columns\n",
    "* bootstrapping\n",
    "* complex imputer\n",
    "* Grid search best models from baseline\n",
    "* Normalize data with yeo-johnson power transformer\n",
    "* perutation importance for features? AML lec 12\n",
    "* try tensor flow?\n",
    "* sklearn missing indicator\n",
    "* run on databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updated Preprocessing\n",
    "* iterative imputer\n",
    "* binary \"missing\" feature cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "\n",
    "def try_model(model, X, y):\n",
    "    scores = cross_val_score(model, X, y, cv=3, scoring='neg_mean_squared_error')\n",
    "    print('Average MSE = {:.2f} +/- {:.2f}'.format(-np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    \n",
    "num_transform = Pipeline(\n",
    "    [\n",
    "        ('num_imputer', IterativeImputer(n_nearest_features=5, random_state=0, add_indicator=True,\n",
    "                                         max_iter=100)),\n",
    "        ('num_scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures())\n",
    "    ]\n",
    ")\n",
    "\n",
    "cat_transform = Pipeline(\n",
    "    [\n",
    "#         ('cat_imputer', IterativeImputer(n_nearest_features=5, initial_strategy='most_frequent', \n",
    "#          add_indicator=True, random_state=0)),\n",
    "        ('nan_imputer', SimpleImputer(strategy='constant', fill_value='missing', add_indicator=True)),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ('cat_scaler', StandardScaler(with_mean=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('num', num_transform, ~categorical_obj_cols),\n",
    "        ('cat', cat_transform, categorical_obj_cols),\n",
    "    ]\n",
    ")\n",
    "    \n",
    "X_train_pr = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Truncated SVD  \n",
    "* I want to try to lower the dimensionality of my data, both to increase speed of training, and hopefully to increase accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 16066)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "tsvd = TruncatedSVD(n_components=X_train_pr.shape[1]-1)\n",
    "X_tsvd = tsvd.fit(X_train_pr)\n",
    "tsvd_var_ratios = tsvd.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "    # Set initial variance explained so far\n",
    "    total_variance = 0.0\n",
    "    \n",
    "    # Set initial number of features\n",
    "    n_components = 0\n",
    "    \n",
    "    # For the explained variance of each feature:\n",
    "    for explained_variance in var_ratio:\n",
    "        \n",
    "        # Add the explained variance to the total\n",
    "        total_variance += explained_variance\n",
    "        \n",
    "        # Add one to the number of components\n",
    "        n_components += 1\n",
    "        \n",
    "        # If we reach our goal level of explained variance\n",
    "        if total_variance >= goal_var:\n",
    "            # End the loop\n",
    "            break\n",
    "            \n",
    "    # Return the number of components\n",
    "    return n_components\n",
    "\n",
    "select_n_components(tsvd_var_ratios, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "tsvd = TruncatedSVD(n_components=1495, random_state=4771)\n",
    "X_tsvd = tsvd.fit_transform(X_train_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 1495)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tsvd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE = 153882.99\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "Xy_train_xgb = xgb.DMatrix(data=X_tsvd, label=y_train)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "params = {\"objective\":\"reg:squarederror\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=Xy_train_xgb, params=params, nfold=3, num_boost_round=50,\n",
    "                    early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=0)\n",
    "\n",
    "mse = cv_results[\"test-rmse-mean\"].tail(1).values[0]**2\n",
    "print('Average MSE = {:.2f}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE = 119662.11\n"
     ]
    }
   ],
   "source": [
    "Xy_train_xgb = xgb.DMatrix(data=X_train_pr, label=y_train)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', \n",
    "                          colsample_bytree = 0.3, \n",
    "                          learning_rate = 0.1,\n",
    "                          max_depth = 5, \n",
    "                          alpha = 10, \n",
    "                          n_estimators = 10)\n",
    "\n",
    "params = {\"objective\":\"reg:squarederror\",\n",
    "          'colsample_bytree': 0.3,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 5, \n",
    "          'min_child_weight': 1,\n",
    "          'alpha': 10,\n",
    "          'eta':0.1,\n",
    "          'subsample': 1\n",
    "         }\n",
    "\n",
    "cv_results = xgb.cv(dtrain=Xy_train_xgb, \n",
    "                    params=params, \n",
    "                    nfold=3, \n",
    "                    num_boost_round=999,\n",
    "                    early_stopping_rounds=10,\n",
    "                    metrics=\"rmse\", \n",
    "                    as_pandas=True, \n",
    "                    seed=0)\n",
    "\n",
    "mse = cv_results[\"test-rmse-mean\"].tail(1).values[0]**2\n",
    "print('Average MSE = {:.2f}'.format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Searching xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train_xgb = xgb.DMatrix(data=X_train_pr, label=y_train)\n",
    "\n",
    "\n",
    "gs_params = []\n",
    "for d in [9,10,11]:\n",
    "    for w in [5,6,7]:\n",
    "        gs_params.append((d,w))\n",
    "    \n",
    "\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', \n",
    "                          colsample_bytree = 0.3, \n",
    "                          learning_rate = 0.1,\n",
    "                          max_depth = 5, \n",
    "                          alpha = 10, \n",
    "                          n_estimators = 10)\n",
    "\n",
    "params = {\"objective\":\"reg:squarederror\",\n",
    "          'colsample_bytree': 0.3,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 5, \n",
    "          'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=Xy_train_xgb, \n",
    "                    params=params, \n",
    "                    nfold=3, \n",
    "                    num_boost_round=999,\n",
    "                    early_stopping_rounds=10,\n",
    "                    metrics=\"rmse\", \n",
    "                    as_pandas=True, \n",
    "                    seed=0)\n",
    "\n",
    "mse = cv_results[\"test-rmse-mean\"].tail(1).values[0]**2\n",
    "print('Average MSE = {:.2f}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Disbursed'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Disbursed'].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Disbursed'], dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lng_home\n",
      "cnt_h\n",
      "cnt_brth\n",
      "reg_tl2\n",
      "v272\n",
      "v52\n",
      "v184\n",
      "v104\n",
      "v135\n",
      "v235\n",
      "v1\n",
      "v63\n",
      "v87\n",
      "v239\n",
      "v224\n",
      "v71\n",
      "v105\n",
      "isic2l\n",
      "isic2c\n",
      "isco2c\n",
      "isco2l\n"
     ]
    }
   ],
   "source": [
    "# high cardinality cols\n",
    "for col in cat_cols:\n",
    "    if len(train[col].unique()) > 50:\n",
    "        print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
