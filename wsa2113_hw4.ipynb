{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.repeat(['train','test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (50,53,54,55,56,255,256,257,258,260,268,376) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_clean = pd.read_csv('hw4-trainingset-wsa2113.csv')\n",
    "train = train_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (50,255,256,257,258,260,268,280) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "test_clean = pd.read_csv('hw4-testset-wsa2113.csv')\n",
    "test = test_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = pd.read_csv('CodeBook-SELECT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (20000, 380)\n",
      "test shape: (24500, 380)\n",
      "code book shape: (379, 2)\n"
     ]
    }
   ],
   "source": [
    "print('train shape:',train.shape)\n",
    "print('test shape:',test.shape)\n",
    "print('code book shape:',cb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:  \n",
    "* create baseline\n",
    "    * drop high null variables and rows\n",
    "* Data cleaning\n",
    "    * drop duplicate columns\n",
    "        * cntryid, cntryid_e\n",
    "        * drop cntryid, as it is less specific\n",
    "    * drop cols w/ high null %\n",
    "    * drop rows w/ high null %\n",
    "    * add is_null column for each category where value was null\n",
    "    * find cols with mixed types and correct\n",
    "    * convert numerical columns to int or float from objects\n",
    "    * categorical variables\n",
    "        * OHC categorical variables\n",
    "        * make sure dtypes match up across train and test\n",
    "    * missing data\n",
    "        * experiment imputing with mean and median\n",
    "            * check distribution of data; if there are big outliers, use median, if not, use mean\n",
    "        * check all cols which have missing data and see if that data should be captured in a new feature\n",
    "    * feature scaling\n",
    "        * **NOTE: split and scale at the same time**\n",
    "        * normalization --> min/max scaler\n",
    "        * standardization (z-score normalization)\n",
    "        * api\n",
    "            * column transformer\n",
    "                * numeric transformer\n",
    "                    * imputer\n",
    "                    * scaler\n",
    "                * categorical transformer\n",
    "                    * imputer\n",
    "                    * OHE\n",
    "    * dimensionality reduction\n",
    "        * PCA\n",
    "    * normalizing\n",
    "        * yeo-johnson power transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "* Remove columns\n",
    "    * Drop high % null cols and rows\n",
    "        * Threshold = 75%\n",
    "    * Drop columns unrelated to performance\n",
    "    * Drop target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split data into train, val, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 377)\n",
      "(20000,)\n",
      "(24500, 377)\n",
      "(24500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = train.drop(['uni','row','job_performance'], axis = 1)\n",
    "y_train = train['job_performance']\n",
    "X_test = test[X_train.columns]\n",
    "y_test = test['job_performance']\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cntryid      United States\n",
       "cntryid_e    United States\n",
       "age_r                   65\n",
       "gender_r              Male\n",
       "lng_bq                 tur\n",
       "                 ...      \n",
       "v81                    125\n",
       "v156                    60\n",
       "v239                  9999\n",
       "v224                  9999\n",
       "v105                  9999\n",
       "Length: 89, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzUAAAI/CAYAAABOAPc+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAeeklEQVR4nO3df4xmV3kf8O9TD5CI0NiGBVle04Fm1YCqAtaWuKKKUhwR7I1iKoFEFBWLWlqphSpRWoWhkdpEaqWlUgNBiohcTGJSEkNIIlssTWIZUNQ/MKyDMQZDvThTvLXLbgo4SVGSkpz+MXfDsJ6Znd19f8yz8/lIr957zz0z88x79s7sd869560xRgAAALr6W8suAAAA4FIINQAAQGtCDQAA0JpQAwAAtCbUAAAArQk1AABAayvLLiBJnve8543V1dVllwEAAOxRDzzwwB+PMQ5sdWxPhJrV1dWcOHFi2WUAAAB7VFX9z+2OufwMAABoTagBAABaE2oAAIDWhBoAAKA1oQYAAGhNqAEAAFoTagAAgNaEGgAAoDWhBgAAaE2oAQAAWhNqAACA1oQaAACgNaEGAABoTagBAABaE2oAAIDWhBoAAKA1oQYAAGhtV6Gmqq6sqg9X1Rer6pGq+kdVdXVV3VtVj07PV019q6reXVUnq+qhqrp+vt8CAACwn+12puYXk/zuGOP7k7wsySNJ1pLcN8Y4lOS+aT9JbkpyaHocTfKemVYMAACwyXlDTVX97SQ/mOSOJBlj/OUY4xtJbkly59TtziSvm7ZvSfL+seGTSa6sqmtmXjkAAEB2N1Pz4iRnkvxKVX2mqt5bVc9O8oIxxpNJMj0/f+p/bZLHN338qakNAABg5nYTalaSXJ/kPWOMVyT5v/n2pWZbqS3axtM6VR2tqhNVdeLMmTO7KhYAAOBcuwk1p5KcGmPcP+1/OBsh56tnLyubnk9v6n/dpo8/mOSJcz/pGOP2McbhMcbhAwcOXGz9AADAPnfeUDPG+N9JHq+qvzc13ZjkC0nuSXLr1HZrkrun7XuSvGlaBe2GJE+dvUwNAABg1lZ22e9fJflAVT0zyWNJ3pyNQPShqrotyVeSvGHq+9EkNyc5meSbU18AYAFW145ve2z92JEFVgKwOLsKNWOMB5Mc3uLQjVv0HUnecol1AQAA7Mpu36cGAABgTxJqAACA1oQaAACgNaEGAABoTagBAABaE2oAAIDWhBoAAKA1oQYAAGhtV2++CQAs1ura8W2PrR87ssBKAPY+MzUAAEBrQg0AANCaUAMAALQm1AAAAK0JNQAAQGtCDQAA0JpQAwAAtCbUAAAArQk1AABAa0INAADQmlADAAC0JtQAAACtrSy7AADYj1bXji+7hO+wUz3rx44ssBKAC2emBgAAaE2oAQAAWhNqAACA1oQaAACgNQsFAMAlcIM9wPKZqQEAAFoTagAAgNaEGgAAoDWhBgAAaE2oAQAAWhNqAACA1oQaAACgNaEGAABoTagBAABaE2oAAIDWhBoAAKA1oQYAAGhNqAEAAFoTagAAgNZWll0AALAYq2vHl10CwFyYqQEAAFozUwMAc2JmBGAxhBoAYC52CnXrx44ssBLgcifUAEAzZoAAvpNQAwDnIUQA7G0WCgAAAFoTagAAgNaEGgAAoDWhBgAAaM1CAQAQiwEAdGamBgAAaE2oAQAAWhNqAACA1oQaAACgNQsFAAAXzQILwF5gpgYAAGhNqAEAAFoTagAAgNaEGgAAoDWhBgAAaE2oAQAAWrOkMwDt7LSM8PqxIwusBIC9wEwNAADQmlADAAC05vIzAGDPcYkhcCHM1AAAAK0JNQAAQGtCDQAA0Jp7agDYN3a6TwOAvszUAAAArQk1AABAa0INAADQmlADAAC0ZqEAAGBHFlgA9jozNQAAQGtCDQAA0NquQk1VrVfV56rqwao6MbVdXVX3VtWj0/NVU3tV1bur6mRVPVRV18/zGwAAAPa3C5mp+SdjjJePMQ5P+2tJ7htjHEpy37SfJDclOTQ9jiZ5z6yKBQAAONelXH52S5I7p+07k7xuU/v7x4ZPJrmyqq65hK8DAACwrd2GmpHk96vqgao6OrW9YIzxZJJMz8+f2q9N8vimjz01tQEAAMzcbpd0ftUY44mqen6Se6vqizv0rS3axtM6bYSjo0nywhe+cJdlAAAAfKddzdSMMZ6Ynk8n+Z0kr0zy1bOXlU3Pp6fup5Jct+nDDyZ5YovPefsY4/AY4/CBAwcu/jsAAAD2tfOGmqp6dlU95+x2ktckeTjJPUlunbrdmuTuafueJG+aVkG7IclTZy9TAwAAmLXdXH72giS/U1Vn+//6GON3q+rTST5UVbcl+UqSN0z9P5rk5iQnk3wzyZtnXjUAAMDkvKFmjPFYkpdt0f5/kty4RftI8paZVAcAAHAel7KkMwAAwNIJNQAAQGtCDQAA0JpQAwAAtCbUAAAArQk1AABAa0INAADQmlADAAC0JtQAAACtCTUAAEBrQg0AANCaUAMAALQm1AAAAK2tLLsAANjK6trxhX4cAH2ZqQEAAFoTagAAgNaEGgAAoDWhBgAAaE2oAQAAWhNqAACA1oQaAACgNaEGAABoTagBAABaE2oAAIDWhBoAAKA1oQYAAGhNqAEAAFoTagAAgNaEGgAAoDWhBgAAaE2oAQAAWltZdgEAwP6zunZ82SUAlxEzNQAAQGtCDQAA0JpQAwAAtCbUAAAArQk1AABAa0INAADQmlADAAC0JtQAAACtCTUAAEBrQg0AANCaUAMAALQm1AAAAK0JNQAAQGsryy4AgMvX6trxHY+vHzuyoEoAuJyZqQEAAFoTagAAgNaEGgAAoDWhBgAAaE2oAQAAWhNqAACA1oQaAACgNaEGAABoTagBAABaW1l2AQDsX6trx5ddAgCXATM1AABAa0INAADQmlADAAC0JtQAAACtCTUAAEBrQg0AANCaUAMAALQm1AAAAK0JNQAAQGsryy4AgN5W144vuwT2mZ3+za0fO7LASoC9wkwNAADQmlADAAC0JtQAAACtCTUAAEBrQg0AANCaUAMAALQm1AAAAK0JNQAAQGtCDQAA0JpQAwAAtLay7AIAAGZlde34tsfWjx1ZYCXAIpmpAQAAWtt1qKmqK6rqM1X1kWn/RVV1f1U9WlUfrKpnTu3PmvZPTsdX51M6AADAhc3U/GSSRzbtvyPJO8cYh5J8PcltU/ttSb4+xvi+JO+c+gEAAMzFrkJNVR1MciTJe6f9SvLqJB+eutyZ5HXT9i3TfqbjN079AQAAZm63MzXvSvIzSf562n9ukm+MMb417Z9Kcu20fW2Sx5NkOv7U1B8AAGDmzrv6WVX9aJLTY4wHquqHzjZv0XXs4tjmz3s0ydEkeeELX7irYgEALpaV0eDytZuZmlcl+bGqWk9yVzYuO3tXkiur6mwoOpjkiWn7VJLrkmQ6/r1JvnbuJx1j3D7GODzGOHzgwIFL+iYAAID967yhZozx9jHGwTHGapI3JvnYGOMnknw8yeunbrcmuXvavmfaz3T8Y2OMp83UAAAAzMKlvE/N25L8dFWdzMY9M3dM7Xckee7U/tNJ1i6tRAAAgO2d956azcYYn0jyiWn7sSSv3KLPnyd5wwxqAwAAOK9LmakBAABYOqEGAABoTagBAABaE2oAAIDWhBoAAKA1oQYAAGhNqAEAAFoTagAAgNaEGgAAoDWhBgAAaE2oAQAAWhNqAACA1oQaAACgNaEGAABoTagBAABaE2oAAIDWhBoAAKC1lWUXAACwbKtrx7c9tn7syAIrAS6GmRoAAKA1oQYAAGjN5WcAnNdOl+YAwLKZqQEAAFoTagAAgNaEGgAAoDWhBgAAaE2oAQAAWhNqAACA1oQaAACgNaEGAABoTagBAABaE2oAAIDWhBoAAKA1oQYAAGhNqAEAAFoTagAAgNaEGgAAoDWhBgAAaE2oAQAAWhNqAACA1oQaAACgNaEGAABobWXZBQCwOKtrx7c9tn7syAIrAYDZMVMDAAC0JtQAAACtCTUAAEBrQg0AANCaUAMAALQm1AAAAK0JNQAAQGtCDQAA0JpQAwAAtLay7AIA2BtW144vuwQAuChmagAAgNaEGgAAoDWhBgAAaE2oAQAAWhNqAACA1oQaAACgNaEGAABoTagBAABa8+abAA3t9EaZ68eOLLASAFg+MzUAAEBrQg0AANCaUAMAALQm1AAAAK0JNQAAQGtCDQAA0JpQAwAAtCbUAAAArQk1AABAayvLLgAAYC9bXTu+7bH1Y0cWWAmwHTM1AABAa0INAADQmlADAAC0JtQAAACtCTUAAEBrQg0AANCaUAMAALR23lBTVd9VVZ+qqs9W1eer6uen9hdV1f1V9WhVfbCqnjm1P2vaPzkdX53vtwAAAOxnu5mp+Yskrx5jvCzJy5O8tqpuSPKOJO8cYxxK8vUkt039b0vy9THG9yV559QPAABgLs4basaGP5t2nzE9RpJXJ/nw1H5nktdN27dM+5mO31hVNbOKAQAANtnVPTVVdUVVPZjkdJJ7k3w5yTfGGN+aupxKcu20fW2Sx5NkOv5UkufOsmgAAICzdhVqxhh/NcZ4eZKDSV6Z5CVbdZuet5qVGec2VNXRqjpRVSfOnDmz23oBAAC+wwWtfjbG+EaSTyS5IcmVVbUyHTqY5Ilp+1SS65JkOv69Sb62xee6fYxxeIxx+MCBAxdXPQAAsO/tZvWzA1V15bT93Ul+OMkjST6e5PVTt1uT3D1t3zPtZzr+sTHG02ZqAAAAZmHl/F1yTZI7q+qKbISgD40xPlJVX0hyV1X9hySfSXLH1P+OJL9WVSezMUPzxjnUDQAAkGQXoWaM8VCSV2zR/lg27q85t/3Pk7xhJtUBAACcxwXdUwMAALDX7ObyMwAaWV07vuwSAGChhBoAgDnY6Q8M68eOLLASuPy5/AwAAGhNqAEAAFoTagAAgNaEGgAAoDWhBgAAaE2oAQAAWhNqAACA1oQaAACgNW++CbBH7fTGfQDAt5mpAQAAWjNTAwBwkcyowt5gpgYAAGhNqAEAAFoTagAAgNaEGgAAoDWhBgAAaE2oAQAAWhNqAACA1oQaAACgNaEGAABoTagBAABaW1l2AQD72era8WWXAADtmakBAABaE2oAAIDWhBoAAKA1oQYAAGhNqAEAAFoTagAAgNaEGgAAoDWhBgAAaE2oAQAAWhNqAACA1oQaAACgNaEGAABoTagBAABaE2oAAIDWhBoAAKA1oQYAAGhNqAEAAFoTagAAgNaEGgAAoDWhBgAAaE2oAQAAWhNqAACA1oQaAACgNaEGAABoTagBAABaE2oAAIDWhBoAAKA1oQYAAGhtZdkFAFzuVteOL7sEALismakBAABaE2oAAIDWhBoAAKA1oQYAAGhNqAEAAFoTagAAgNaEGgAAoDWhBgAAaE2oAQAAWhNqAACA1oQaAACgtZVlFwAAsN+srh3f9tj6sSMLrAQuD2ZqAACA1oQaAACgNaEGAABoTagBAABaE2oAAIDWhBoAAKA1oQYAAGhNqAEAAFoTagAAgNaEGgAAoDWhBgAAaO28oaaqrquqj1fVI1X1+ar6yan96qq6t6oenZ6vmtqrqt5dVSer6qGqun7e3wQAALB/7Wam5ltJ/vUY4yVJbkjylqp6aZK1JPeNMQ4luW/aT5KbkhyaHkeTvGfmVQMAAEzOG2rGGE+OMf5w2v7TJI8kuTbJLUnunLrdmeR10/YtSd4/NnwyyZVVdc3MKwcAAEiyciGdq2o1ySuS3J/kBWOMJ5ON4FNVz5+6XZvk8U0fdmpqe/JSiwVYltW149seWz92ZIGVAADn2vVCAVX1PUl+K8lPjTH+ZKeuW7SNLT7f0ao6UVUnzpw5s9syAAAAvsOuQk1VPSMbgeYDY4zfnpq/evaysun59NR+Ksl1mz78YJInzv2cY4zbxxiHxxiHDxw4cLH1AwAA+9xuVj+rJHckeWSM8QubDt2T5NZp+9Ykd29qf9O0CtoNSZ46e5kaAADArO3mnppXJflnST5XVQ9Obf82ybEkH6qq25J8JckbpmMfTXJzkpNJvpnkzTOtGAAAYJPzhpoxxn/P1vfJJMmNW/QfSd5yiXUBAADsyq4XCgAAANiLhBoAAKA1oQYAAGhNqAEAAFoTagAAgNZ2s6QzADtYXTu+7BIAYF8zUwMAALQm1AAAAK25/AwAYA+5lEta148dmWEl0IeZGgAAoDWhBgAAaE2oAQAAWhNqAACA1oQaAACgNaEGAABoTagBAABaE2oAAIDWhBoAAKC1lWUXALBIO71Tt3fiBoCezNQAAACtCTUAAEBrQg0AANCaUAMAALQm1AAAAK0JNQAAQGtCDQAA0JpQAwAAtCbUAAAArQk1AABAa0INAADQ2sqyCwCYtdW14wv9OABguczUAAAArQk1AABAa0INAADQmlADAAC0JtQAAACtCTUAAEBrQg0AANCaUAMAALQm1AAAAK0JNQAAQGtCDQAA0JpQAwAAtCbUAAAArQk1AABAa0INAADQmlADAAC0JtQAAACtCTUAAEBrQg0AANCaUAMAALQm1AAAAK2tLLsAAABmY3Xt+LbH1o8dWWAlsFhCDdDSTr+4AYD9xeVnAABAa0INAADQmlADAAC0JtQAAACtCTUAAEBrQg0AANCaJZ0BAPYB72HD5cxMDQAA0JpQAwAAtCbUAAAArQk1AABAa0INAADQmlADAAC0JtQAAACtCTUAAEBrQg0AANDayrILAABguVbXjm97bP3YkQVWAhfHTA0AANCaUAMAALQm1AAAAK0JNQAAQGtCDQAA0JpQAwAAtCbUAAAArZ031FTV+6rqdFU9vKnt6qq6t6oenZ6vmtqrqt5dVSer6qGqun6exQMAAOxmpuZXk7z2nLa1JPeNMQ4luW/aT5KbkhyaHkeTvGc2ZQIAAGxt5Xwdxhh/UFWr5zTfkuSHpu07k3wiydum9vePMUaST1bVlVV1zRjjyVkVDPTjnaoBgHm62HtqXnA2qEzPz5/ar03y+KZ+p6Y2AACAuZj1QgG1RdvYsmPV0ao6UVUnzpw5M+MyAACA/eJiQ81Xq+qaJJmeT0/tp5Jct6nfwSRPbPUJxhi3jzEOjzEOHzhw4CLLAAAA9rvz3lOzjXuS3Jrk2PR896b2t1bVXUl+IMlT7qcBduJ+GwDgUp031FTVb2RjUYDnVdWpJP8+G2HmQ1V1W5KvJHnD1P2jSW5OcjLJN5O8eQ41AwAA/I3drH7249scunGLviPJWy61KAAAgN2a9UIBAAAACyXUAAAArQk1AABAaxe7+hlwGdprK5HtVA8AwFlCDQAA29prf/CCrbj8DAAAaE2oAQAAWnP5GTAT7n8BAJbFTA0AANCaUAMAALQm1AAAAK0JNQAAQGsWCgB2xUIAAMBeZaYGAABoTagBAABaE2oAAIDW3FMD+4x7YwCAy42ZGgAAoDUzNdDUTjMu68eOLLASAIDlMlMDAAC0JtQAAACtCTUAAEBrQg0AANCaUAMAALQm1AAAAK0JNQAAQGtCDQAA0JpQAwAAtLay7AKA7a2uHV92CQCwrZ1+T60fO7LAStjvzNQAAACtCTUAAEBrQg0AANCaUAMAALQm1AAAAK0JNQAAQGtCDQAA0Jr3qYHLkPe3AQD2E6EGFsCbkwEAzI/LzwAAgNbM1MCSuVQMAODSmKkBAABaE2oAAIDWhBoAAKA1oQYAAGhNqAEAAFqz+hn7zrzeM8YqZgAAyyHUAAAwc954mkUSagAA2DOEIS6GUAMXwCVmAAB7j1ADmwgtAAD9WP0MAABoTagBAABaE2oAAIDWhBoAAKA1oQYAAGhNqAEAAFoTagAAgNaEGgAAoDVvvsmettObYa4fO3JRHwcALJff08yamRoAAKA1oQYAAGhNqAEAAFoTagAAgNaEGgAAoLUaYyy7hhw+fHicOHFi2WWwJFZAAQBmYaeVUemvqh4YYxze6pglnQEAuCxc7FtB0J9Qc5lyUgMAsF8INcyMIAUAwDJYKAAAAGhNqAEAAFpz+RlP4zIyAAA6EWpYCMs2AwDLdLH/F/EH3R6EmsYEBQAAcE8NAADQnJmafehSZnjMDgEAsNeYqQEAAFoTagAAgNZcfgYAANuYx6X3VlSbvbmEmqp6bZJfTHJFkveOMY7N4+sswzzew8V9KgAA+4f3BJy9mV9+VlVXJPmlJDcleWmSH6+ql8766wAAACTzmal5ZZKTY4zHkqSq7kpyS5IvzOFr7SlmXAAAmJdL+b/m5T4DNI9Qc22Sxzftn0ryA3P4OnMjnAAAsF9cDpfDzSPU1BZt42mdqo4mOTrt/llVfWkGX/t5Sf54Bp+HS2cs9g5jsXcYi73BOOwdxmLvMBZ7RL1jPmNR71jsx83J39nuwDxCzakk123aP5jkiXM7jTFuT3L7LL9wVZ0YYxye5efk4hiLvcNY7B3GYm8wDnuHsdg7jMXeYSwuzjzep+bTSQ5V1Yuq6plJ3pjknjl8HQAAgNnP1IwxvlVVb03ye9lY0vl9Y4zPz/rrAAAAJHN6n5oxxkeTfHQen/s8Zno5G5fEWOwdxmLvMBZ7g3HYO4zF3mEs9g5jcRFqjKfdww8AANDGPO6pAQAAWJh2oaaq1qvqc1X1YFWdmNqurqp7q+rR6fmqqb2q6t1VdbKqHqqq65dbfW9V9b6qOl1VD29qu+DXvqpunfo/WlW3LuN76Wybcfi5qvpf03nxYFXdvOnY26dx+FJV/cim9tdObSeram3R38floKquq6qPV9UjVfX5qvrJqd15sWA7jIVzY4Gq6ruq6lNV9dlpHH5+an9RVd0//fv+4LSQUKrqWdP+yen46qbPteX4sDs7jMWvVtUfbTonXj61+/k0Z1V1RVV9pqo+Mu07L2ZpjNHqkWQ9yfPOaftPSdam7bUk75i2b07y37Lx3jk3JLl/2fV3fiT5wSTXJ3n4Yl/7JFcneWx6vmravmrZ31unxzbj8HNJ/s0WfV+a5LNJnpXkRUm+nI0FPK6Ytl+c5JlTn5cu+3vr9khyTZLrp+3nJPkf02vuvNg7Y+HcWOw4VJLvmbafkeT+6d/6h5K8cWr/5ST/Ytr+l0l+edp+Y5IP7jQ+y/7+Oj12GItfTfL6Lfr7+TT/MfnpJL+e5CPTvvNiho92MzXbuCXJndP2nUlet6n9/WPDJ5NcWVXXLKPAy8EY4w+SfO2c5gt97X8kyb1jjK+NMb6e5N4kr51/9ZePbcZhO7ckuWuM8RdjjD9KcjLJK6fHyTHGY2OMv0xy19SXCzDGeHKM8YfT9p8meSTJtXFeLNwOY7Ed58YcTP+2/2zafcb0GEleneTDU/u558TZc+XDSW6sqsr248Mu7TAW2/HzaY6q6mCSI0neO+1XnBcz1THUjCS/X1UPVNXRqe0FY4wnk41fbEmeP7Vfm+TxTR97Kjv/kuPCXehrb0zm563TJQPvO3u5U4zDwkyXB7wiG38NdV4s0TljkTg3Fmq6xObBJKez8R/gLyf5xhjjW1OXza/p37ze0/Gnkjw3xmEmzh2LMcbZc+I/TufEO6vqWVObc2K+3pXkZ5L89bT/3DgvZqpjqHnVGOP6JDcleUtV/eAOfWuLNsu9LcZ2r70xmY/3JPm7SV6e5Mkk/3lqNw4LUFXfk+S3kvzUGONPduq6RZvxmKEtxsK5sWBjjL8aY7w8ycFs/BX5JVt1m56NwxydOxZV9feTvD3J9yf5h9m4pOxtU3djMSdV9aNJTo8xHtjcvEVX58UlaBdqxhhPTM+nk/xONn5gfvXsZWXT8+mp+6kk12368INJnlhctfvChb72xmQOxhhfnX55/XWS/5JvT0cbhzmrqmdk4z/RHxhj/PbU7LxYgq3GwrmxPGOMbyT5RDbuz7iyqs6+N97m1/RvXu/p+Pdm4/Ja4zBDm8bitdOlmmOM8RdJfiXOiUV4VZIfq6r1bFzS+upszNw4L2aoVaipqmdX1XPObid5TZKHk9yT5OxqHLcmuXvavifJm6YVPW5I8tTZS0KYmQt97X8vyWuq6qrpMpDXTG1cgnPuFfun2Tgvko1xeOO0ksqLkhxK8qkkn05yaFp55ZnZuBHxnkXWfDmYrnG+I8kjY4xf2HTIebFg242Fc2OxqupAVV05bX93kh/Oxv1NH0/y+qnbuefE2XPl9Uk+NsYY2X582KVtxuKLm/7gUtm4h2PzOeHn0xyMMd4+xjg4xljNxs+Uj40xfiLOi9max+oD83pkYzWaz06Pzyf52an9uUnuS/Lo9Hz11F5Jfikb1/N+LsnhZX8PnR9JfiMbl2/8v2z8teC2i3ntk/zzbNzcdjLJm5f9fXV7bDMOvza9zg9l44feNZv6/+w0Dl9KctOm9puzsULUl8+eSx4XPBb/OBtT/w8leXB63Oy82FNj4dxY7Dj8gySfmV7vh5P8u6n9xdn4z9fJJL+Z5FlT+3dN+yen4y8+3/h4XPJYfGw6Jx5O8l/z7RXS/HxazLj8UL69+pnzYoaPml4gAACAllpdfgYAAHAuoQYAAGhNqAEAAFoTagAAgNaEGgAAoDWhBgAAaE2oAQAAWhNqAACA1v4/8fOm7YSCH4cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,10))\n",
    "_ = ax.hist(y_train, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Identify categorical and numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_obj_cols = X_train.dtypes == object\n",
    "cat_cols = categorical_obj_cols[categorical_obj_cols==True].index.values\n",
    "num_cols = categorical_obj_cols[categorical_obj_cols==False].index.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fix columns with multiple data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    X_train[col] = X_train[col].astype('str')\n",
    "    \n",
    "for col in num_cols:\n",
    "    X_train[col] = X_train[col].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipeline\n",
    "    * impute nulls\n",
    "    * scale numerical columns\n",
    "    * OHE categorical columns\n",
    "    * Try with\n",
    "        * Lasso\n",
    "        * Ridge\n",
    "        * RandomForestRegressor\n",
    "        * SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def try_model(model, X, y):\n",
    "    scores = cross_val_score(model, X, y, cv=3, scoring='neg_mean_squared_error')\n",
    "    print('Average MSE = {:.2f} +/- {:.2f}'.format(-np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    \n",
    "# missing_transform = \n",
    "num_transform = Pipeline(\n",
    "    [\n",
    "        ('num_imputer', SimpleImputer(strategy='median')),\n",
    "        ('num_scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures())\n",
    "    ]\n",
    ")\n",
    "\n",
    "cat_transform = Pipeline(\n",
    "    [\n",
    "        ('nan_imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ('cat_scaler', StandardScaler(with_mean=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('num', num_transform, ~categorical_obj_cols),\n",
    "        ('cat', cat_transform, categorical_obj_cols),\n",
    "    ]\n",
    ")\n",
    "    \n",
    "# X_train_pr = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 6665)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso_alphas = np.logspace(-1, -.01, 10)\n",
    "lasso = LassoCV(alphas=lasso_alphas, cv=3, max_iter=10000, n_jobs=-1, random_state=0)\n",
    "lasso.fit(X_train_pr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_data = np.hstack((lasso.mse_path_,lasso.alphas_[:,np.newaxis]))\n",
    "lasso_data = np.hstack((lasso_data, \n",
    "                        np.array([lasso.alpha_ for _ in range(lasso.mse_path_.shape[0])])[:,np.newaxis]))\n",
    "lasso_cols = ['cv_'+str(i) for i in range(lasso.mse_path_.shape[1])]\n",
    "lasso_cols.append('alpha')\n",
    "lasso_cols.append('best_alpha')\n",
    "lasso_results = pd.DataFrame(data=lasso_data, columns=lasso_cols)\n",
    "lasso_results.to_csv('lasso_results.csv')\n",
    "lasso_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE = 124874.70 +/- 5820.21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "best_lasso_alpha = 0.977237\n",
    "best_lasso = Lasso(alpha=best_lasso_alpha, normalize=False, random_state=0)\n",
    "scores = cross_val_score(best_lasso, X_train_pr, y_train, cv=3, scoring='neg_mean_squared_error')\n",
    "print('Average MSE = {:.2f} +/- {:.2f}'.format(-np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([ 900.,  960., 1020., 1080., 1140., 1200., 1260., 1320., 1380.,\n",
       "       1440., 1500.]),\n",
       "    cv=None, fit_intercept=True, gcv_mode=None, normalize=False,\n",
       "    scoring=None, store_cv_values=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# ridge_alphas = np.logspace(-4, .01, 20)\n",
    "ridge_alphas = np.linspace(900,1500,11)\n",
    "ridge = RidgeCV(alphas=ridge_alphas, store_cv_values=True)\n",
    "ridge.fit(X_train_pr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv_results = np.mean(ridge.cv_values_, axis=0)[:,np.newaxis]\n",
    "ridge_data = np.hstack((ridge_cv_results,ridge_alphas[:,np.newaxis]))\n",
    "ridge_data = np.hstack((ridge_data, \n",
    "                        np.array([ridge.alpha_ for _ in range(ridge_data.shape[0])])[:,np.newaxis]))\n",
    "ridge_cols = ['mse','alpha','best_alpha']\n",
    "ridge_results = pd.DataFrame(data=ridge_data, columns=ridge_cols)\n",
    "ridge_results.to_csv('ridge_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE = 366209.79 +/- 314504.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "best_ridge_alpha = ridge.alpha_\n",
    "best_ridge = Ridge(alpha=best_ridge_alpha, random_state=0)\n",
    "scores = cross_val_score(best_ridge, X_train_pr, y_train, cv=3, scoring='neg_mean_squared_error')\n",
    "print('Average MSE = {:.2f} +/- {:.2f}'.format(-np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF Regressor  \n",
    "* Guidance on gridsearching RandomForestRegressor : https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap\n",
    "              }\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "rscv = RandomizedSearchCV(\n",
    "    rfr,\n",
    "    param_distributions=random_grid,\n",
    "    n_iter=100,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "rscv.fit(X_train_pr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results=pd.DataFrame(rscv.cv_results)\n",
    "rf_results.to_csv('rf_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE = 120600.63\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "Xy_train_xgb = xgb.DMatrix(data=X_train_pr, label=y_train)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "params = {\"objective\":\"reg:squarederror\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=Xy_train_xgb, params=params, nfold=3, num_boost_round=50,\n",
    "                    early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "\n",
    "mse = cv_results[\"test-rmse-mean\"].tail(1).values[0]**2\n",
    "print('Average MSE = {:.2f}'.format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take 2  \n",
    "* univariate statistics\n",
    "* Incorporate PCA into pipeline\n",
    "* Create new encoding for high cardinality categorical columns\n",
    "* add missing value column for np.nan values\n",
    "* Add feature interactions for numerical columns\n",
    "* bootstrapping\n",
    "* complex imputer\n",
    "* Grid search best models from baseline\n",
    "* Normalize data with yeo-johnson power transformer\n",
    "* perutation importance for features? AML lec 12\n",
    "* try tensor flow?\n",
    "* sklearn missing indicator\n",
    "* run on databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updated Preprocessing\n",
    "* iterative imputer\n",
    "* binary \"missing\" feature cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "\n",
    "def try_model(model, X, y):\n",
    "    scores = cross_val_score(model, X, y, cv=3, scoring='neg_mean_squared_error')\n",
    "    print('Average MSE = {:.2f} +/- {:.2f}'.format(-np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    \n",
    "num_transform = Pipeline(\n",
    "    [\n",
    "        ('num_imputer', IterativeImputer(n_nearest_features=5, random_state=0, add_indicator=True,\n",
    "                                         max_iter=100)),\n",
    "        ('num_scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures())\n",
    "    ]\n",
    ")\n",
    "\n",
    "cat_transform = Pipeline(\n",
    "    [\n",
    "#         ('cat_imputer', IterativeImputer(n_nearest_features=5, initial_strategy='most_frequent', \n",
    "#          add_indicator=True, random_state=0)),\n",
    "        ('nan_imputer', SimpleImputer(strategy='constant', fill_value='missing', add_indicator=True)),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ('cat_scaler', StandardScaler(with_mean=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('num', num_transform, ~categorical_obj_cols),\n",
    "        ('cat', cat_transform, categorical_obj_cols),\n",
    "    ]\n",
    ")\n",
    "    \n",
    "X_train_pr = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Truncated SVD  \n",
    "* I want to try to lower the dimensionality of my data, both to increase speed of training, and hopefully to increase accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 16066)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "tsvd = TruncatedSVD(n_components=X_train_pr.shape[1]-1)\n",
    "X_tsvd = tsvd.fit(X_train_pr)\n",
    "tsvd_var_ratios = tsvd.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "    # Set initial variance explained so far\n",
    "    total_variance = 0.0\n",
    "    \n",
    "    # Set initial number of features\n",
    "    n_components = 0\n",
    "    \n",
    "    # For the explained variance of each feature:\n",
    "    for explained_variance in var_ratio:\n",
    "        \n",
    "        # Add the explained variance to the total\n",
    "        total_variance += explained_variance\n",
    "        \n",
    "        # Add one to the number of components\n",
    "        n_components += 1\n",
    "        \n",
    "        # If we reach our goal level of explained variance\n",
    "        if total_variance >= goal_var:\n",
    "            # End the loop\n",
    "            break\n",
    "            \n",
    "    # Return the number of components\n",
    "    return n_components\n",
    "\n",
    "select_n_components(tsvd_var_ratios, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "tsvd = TruncatedSVD(n_components=1495, random_state=4771)\n",
    "X_tsvd = tsvd.fit_transform(X_train_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 1495)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tsvd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/barmfield/anaconda3/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE = 153882.99\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "Xy_train_xgb = xgb.DMatrix(data=X_tsvd, label=y_train)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "params = {\"objective\":\"reg:squarederror\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=Xy_train_xgb, params=params, nfold=3, num_boost_round=50,\n",
    "                    early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=0)\n",
    "\n",
    "mse = cv_results[\"test-rmse-mean\"].tail(1).values[0]**2\n",
    "print('Average MSE = {:.2f}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE = 119662.11\n"
     ]
    }
   ],
   "source": [
    "Xy_train_xgb = xgb.DMatrix(data=X_train_pr, label=y_train)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', \n",
    "                          colsample_bytree = 0.3, \n",
    "                          learning_rate = 0.1,\n",
    "                          max_depth = 5, \n",
    "                          alpha = 10, \n",
    "                          n_estimators = 10)\n",
    "\n",
    "params = {\"objective\":\"reg:squarederror\",\n",
    "          'colsample_bytree': 0.3,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 5, \n",
    "          'min_child_weight': 1,\n",
    "          'alpha': 10,\n",
    "          'eta':0.1,\n",
    "          'subsample': 1\n",
    "         }\n",
    "\n",
    "cv_results = xgb.cv(dtrain=Xy_train_xgb, \n",
    "                    params=params, \n",
    "                    nfold=3, \n",
    "                    num_boost_round=999,\n",
    "                    early_stopping_rounds=10,\n",
    "                    metrics=\"rmse\", \n",
    "                    as_pandas=True, \n",
    "                    seed=0)\n",
    "\n",
    "mse = cv_results[\"test-rmse-mean\"].tail(1).values[0]**2\n",
    "print('Average MSE = {:.2f}'.format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Searching xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train_xgb = xgb.DMatrix(data=X_train_pr, label=y_train)\n",
    "\n",
    "\n",
    "gs_params = []\n",
    "for d in [9,10,11]:\n",
    "    for w in [5,6,7]:\n",
    "        gs_params.append((d,w))\n",
    "    \n",
    "\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', \n",
    "                          colsample_bytree = 0.3, \n",
    "                          learning_rate = 0.1,\n",
    "                          max_depth = 5, \n",
    "                          alpha = 10, \n",
    "                          n_estimators = 10)\n",
    "\n",
    "params = {\"objective\":\"reg:squarederror\",\n",
    "          'colsample_bytree': 0.3,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 5, \n",
    "          'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=Xy_train_xgb, \n",
    "                    params=params, \n",
    "                    nfold=3, \n",
    "                    num_boost_round=999,\n",
    "                    early_stopping_rounds=10,\n",
    "                    metrics=\"rmse\", \n",
    "                    as_pandas=True, \n",
    "                    seed=0)\n",
    "\n",
    "mse = cv_results[\"test-rmse-mean\"].tail(1).values[0]**2\n",
    "print('Average MSE = {:.2f}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Disbursed'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Disbursed'].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Disbursed'], dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lng_home\n",
      "cnt_h\n",
      "cnt_brth\n",
      "reg_tl2\n",
      "v272\n",
      "v52\n",
      "v184\n",
      "v104\n",
      "v135\n",
      "v235\n",
      "v1\n",
      "v63\n",
      "v87\n",
      "v239\n",
      "v224\n",
      "v71\n",
      "v105\n",
      "isic2l\n",
      "isic2c\n",
      "isco2c\n",
      "isco2l\n"
     ]
    }
   ],
   "source": [
    "# high cardinality cols\n",
    "for col in cat_cols:\n",
    "    if len(train[col].unique()) > 50:\n",
    "        print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
